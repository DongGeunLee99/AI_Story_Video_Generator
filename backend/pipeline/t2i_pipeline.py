"""Text-to-Image íŒŒì´í”„ë¼ì¸ - í…ìŠ¤íŠ¸ë¥¼ ì±•í„°ë¡œ ë¶„í• í•˜ê³  ê° ì±•í„°ì— ëŒ€í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""

import json
import os
import time
from typing import Any, Dict, List, Optional

from utils.auth import get_openai_client
from utils.img_gen_prompt import (
    collect_meta_from_chapter,
    build_prompt_from_meta,
    generate_and_save_image,
    get_default_img_prompt,
)
from utils.time_utils import log_time_status


def t2i_pipe(
    input_text: str,
    output_dir: str,
    img_prompt_json: Optional[str] = None,
    img_size: str = "1536x1024",
    img_quality: str = "low",
    total_start: Optional[float] = None,
) -> tuple[List[Dict[str, Any]], str]:
    """
    Text-to-Image íŒŒì´í”„ë¼ì¸
    
    ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì±•í„°ë¡œ ë¶„í• í•˜ê³ , ê° ì±•í„°ì— ëŒ€í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ëª¨ë“  ê²½ë¡œ ì„¤ì •ê³¼ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”ëŠ” ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
    
    Args:
        input_text: ì…ë ¥ í…ìŠ¤íŠ¸
        output_dir: ì¶œë ¥ ë””ë ‰í„°ë¦¬ (ì ˆëŒ€ ê²½ë¡œ ê¶Œì¥)
        img_prompt_json: ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ JSON (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        img_size: ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’: "1536x1024")
        img_quality: ì´ë¯¸ì§€ í’ˆì§ˆ (ê¸°ë³¸ê°’: "low")
        total_start: ì „ì²´ ì‹œì‘ ì‹œê°„ (ì„ íƒì‚¬í•­, ë¡œê¹…ìš©)
        
    Returns:
        (chapters, chapters_json_path) íŠœí”Œ
        - chapters: ì±•í„° ë¦¬ìŠ¤íŠ¸
        - chapters_json_path: ì±•í„° JSON íŒŒì¼ ê²½ë¡œ
    """
    if total_start is None:
        total_start = time.time()
    
    # ì¶œë ¥ ë””ë ‰í„°ë¦¬ ì¤€ë¹„
    output_dir = os.path.abspath(output_dir)
    os.makedirs(output_dir, exist_ok=True)
    
    # ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    if img_prompt_json is None:
        img_prompt_json = get_default_img_prompt()
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = get_openai_client()
    
    # ì±•í„° JSON ê²½ë¡œ ì„¤ì •
    chapters_json_path = os.path.join(output_dir, "chapters_output.json")
    
    # 1) ëª¨ë¸ í˜¸ì¶œ
    log_time_status(total_start, "ëª¨ë¸ í˜¸ì¶œ ì‹œì‘")
    inference_input = img_prompt_json + "\n\n" + input_text
    
    try:
        response = client.responses.create(
            model="gpt-4o-mini",
            input=inference_input,
            timeout=300
        )
    except Exception:
        raise RuntimeError("Inference TIME_OUT")
    
    # ëª¨ë¸ ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì €ì¥
    model_response_text = response.output_text[8:-3:]
    output_txt_path = os.path.join(output_dir, "model_response_output.txt")
    with open(output_txt_path, "w", encoding="utf-8") as f:
        f.write(model_response_text)
    print(f"âœ… ëª¨ë¸ ì‘ë‹µ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {output_txt_path}")
    log_time_status(total_start, "ëª¨ë¸ í˜¸ì¶œ ì™„ë£Œ")
    
    # 2) JSON íŒŒì‹±
    log_time_status(total_start, "JSONìœ¼ë¡œ ë³€í™˜ ì‹œì‘")
    import re
    
    # Responses API êµ¬ì¡°ì—ì„œ ëª¨ë“  text ìˆ˜ì§‘
    text_chunks = []
    if hasattr(response, "output"):
        for msg in response.output:
            if hasattr(msg, "content"):
                for c in msg.content:
                    if hasattr(c, "text") and c.text:
                        text_chunks.append(c.text)
    
    if not text_chunks:
        raise ValueError("ëª¨ë¸ ì‘ë‹µì— í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    raw_text = "\n".join(text_chunks).strip()
    
    # ```json ì½”ë“œë¸”ë¡ ì œê±°
    raw_text = re.sub(r"```json\s*", "", raw_text, flags=re.IGNORECASE)
    raw_text = re.sub(r"\s*```", "", raw_text)
    
    # JSON ì¤‘ê´„í˜¸ ë¸”ë¡ ì¶”ì¶œ
    match = re.search(r"\{[\s\S]*\}", raw_text)
    if not match:
        raise ValueError(
            "ëª¨ë¸ ì‘ë‹µì—ì„œ JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
            f"ì›ë³¸ ì‘ë‹µ:\n{raw_text}"
        )
    
    json_text = match.group(0)
    
    # JSON íŒŒì‹±
    try:
        story_json = json.loads(json_text)
    except json.JSONDecodeError as e:
        raise ValueError(
            f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}\n\n"
            f"ì¶”ì¶œëœ JSON:\n{json_text}"
        )
    
    log_time_status(total_start, "JSONìœ¼ë¡œ ë³€í™˜ ì™„ë£Œ")
    
    # 3) ì±•í„° ì²˜ë¦¬
    log_time_status(total_start, "ì±•í„° êµ¬ë¶„ ì‹œì‘")
    chapters = story_json.get("chapters", [])
    if not chapters:
        raise ValueError("ì±•í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"ì±•í„° ìˆ˜: {len(chapters)}")
    os.makedirs(os.path.dirname(chapters_json_path), exist_ok=True)
    with open(chapters_json_path, "w", encoding="utf-8") as f:
        json.dump(chapters, f, ensure_ascii=False, indent=2)
    log_time_status(total_start, "ì±•í„° êµ¬ë¶„ ì™„ë£Œ")
    
    # 4) ì´ë¯¸ì§€ ìƒì„±
    log_time_status(total_start, "ì´ë¯¸ì§€ ìƒì„± ì‹œì‘")
    for ch in chapters:
        meta = collect_meta_from_chapter(ch)
        prompt = build_prompt_from_meta(meta)
        filename = f"{ch['chapter_number']}_{ch.get('chapter_title', 'chapter')}.png"
        
        log_time_status(total_start, f"ì´ë¯¸ì§€ ì´ë¦„: {filename}")
        
        saved_path = generate_and_save_image(
            client,
            prompt,
            save_dir=output_dir,
            filename=filename,
            size=img_size,
            quality=img_quality
        )
        
        log_time_status(total_start, f"ì €ì¥ ì™„ë£Œ: {saved_path}")
    
    log_time_status(total_start, "ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
    print("ğŸ–¼ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
    
    return chapters, chapters_json_path
